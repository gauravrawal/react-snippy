{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.parse = void 0;\n\nvar tslib_1 = require(\"tslib\");\n\nvar assert_1 = tslib_1.__importDefault(require(\"assert\"));\n\nvar types = tslib_1.__importStar(require(\"ast-types\"));\n\nvar b = types.builders;\nvar isObject = types.builtInTypes.object;\nvar isArray = types.builtInTypes.array;\n\nvar options_1 = require(\"./options\");\n\nvar lines_1 = require(\"./lines\");\n\nvar comments_1 = require(\"./comments\");\n\nvar util = tslib_1.__importStar(require(\"./util\"));\n\nfunction parse(source, options) {\n  options = options_1.normalize(options);\n  var lines = lines_1.fromString(source, options);\n  var sourceWithoutTabs = lines.toString({\n    tabWidth: options.tabWidth,\n    reuseWhitespace: false,\n    useTabs: false\n  });\n  var comments = [];\n  var ast = options.parser.parse(sourceWithoutTabs, {\n    jsx: true,\n    loc: true,\n    locations: true,\n    range: options.range,\n    comment: true,\n    onComment: comments,\n    tolerant: util.getOption(options, \"tolerant\", true),\n    ecmaVersion: 6,\n    sourceType: util.getOption(options, \"sourceType\", \"module\")\n  }); // Use ast.tokens if possible, and otherwise fall back to the Esprima\n  // tokenizer. All the preconfigured ../parsers/* expose ast.tokens\n  // automatically, but custom parsers might need additional configuration\n  // to avoid this fallback.\n\n  var tokens = Array.isArray(ast.tokens) ? ast.tokens : require(\"esprima\").tokenize(sourceWithoutTabs, {\n    loc: true\n  }); // We will reattach the tokens array to the file object below.\n\n  delete ast.tokens; // Make sure every token has a token.value string.\n\n  tokens.forEach(function (token) {\n    if (typeof token.value !== \"string\") {\n      token.value = lines.sliceString(token.loc.start, token.loc.end);\n    }\n  });\n\n  if (Array.isArray(ast.comments)) {\n    comments = ast.comments;\n    delete ast.comments;\n  }\n\n  if (ast.loc) {\n    // If the source was empty, some parsers give loc.{start,end}.line\n    // values of 0, instead of the minimum of 1.\n    util.fixFaultyLocations(ast, lines);\n  } else {\n    ast.loc = {\n      start: lines.firstPos(),\n      end: lines.lastPos()\n    };\n  }\n\n  ast.loc.lines = lines;\n  ast.loc.indent = 0;\n  var file;\n  var program;\n\n  if (ast.type === \"Program\") {\n    program = ast; // In order to ensure we reprint leading and trailing program\n    // comments, wrap the original Program node with a File node. Only\n    // ESTree parsers (Acorn and Esprima) return a Program as the root AST\n    // node. Most other (Babylon-like) parsers return a File.\n\n    file = b.file(ast, options.sourceFileName || null);\n    file.loc = {\n      start: lines.firstPos(),\n      end: lines.lastPos(),\n      lines: lines,\n      indent: 0\n    };\n  } else if (ast.type === \"File\") {\n    file = ast;\n    program = file.program;\n  } // Expose file.tokens unless the caller passed false for options.tokens.\n\n\n  if (options.tokens) {\n    file.tokens = tokens;\n  } // Expand the Program's .loc to include all comments (not just those\n  // attached to the Program node, as its children may have comments as\n  // well), since sometimes program.loc.{start,end} will coincide with the\n  // .loc.{start,end} of the first and last *statements*, mistakenly\n  // excluding comments that fall outside that region.\n\n\n  var trueProgramLoc = util.getTrueLoc({\n    type: program.type,\n    loc: program.loc,\n    body: [],\n    comments: comments\n  }, lines);\n  program.loc.start = trueProgramLoc.start;\n  program.loc.end = trueProgramLoc.end; // Passing file.program here instead of just file means that initial\n  // comments will be attached to program.body[0] instead of program.\n\n  comments_1.attach(comments, program.body.length ? file.program : file, lines); // Return a copy of the original AST so that any changes made may be\n  // compared to the original.\n\n  return new TreeCopier(lines, tokens).copy(file);\n}\n\nexports.parse = parse;\n\nvar TreeCopier = function TreeCopier(lines, tokens) {\n  assert_1.default.ok(this instanceof TreeCopier);\n  this.lines = lines;\n  this.tokens = tokens;\n  this.startTokenIndex = 0;\n  this.endTokenIndex = tokens.length;\n  this.indent = 0;\n  this.seen = new Map();\n};\n\nvar TCp = TreeCopier.prototype;\n\nTCp.copy = function (node) {\n  if (this.seen.has(node)) {\n    return this.seen.get(node);\n  }\n\n  if (isArray.check(node)) {\n    var copy_1 = new Array(node.length);\n    this.seen.set(node, copy_1);\n    node.forEach(function (item, i) {\n      copy_1[i] = this.copy(item);\n    }, this);\n    return copy_1;\n  }\n\n  if (!isObject.check(node)) {\n    return node;\n  }\n\n  util.fixFaultyLocations(node, this.lines);\n  var copy = Object.create(Object.getPrototypeOf(node), {\n    original: {\n      // Provide a link from the copy to the original.\n      value: node,\n      configurable: false,\n      enumerable: false,\n      writable: true\n    }\n  });\n  this.seen.set(node, copy);\n  var loc = node.loc;\n  var oldIndent = this.indent;\n  var newIndent = oldIndent;\n  var oldStartTokenIndex = this.startTokenIndex;\n  var oldEndTokenIndex = this.endTokenIndex;\n\n  if (loc) {\n    // When node is a comment, we set node.loc.indent to\n    // node.loc.start.column so that, when/if we print the comment by\n    // itself, we can strip that much whitespace from the left margin of\n    // the comment. This only really matters for multiline Block comments,\n    // but it doesn't hurt for Line comments.\n    if (node.type === \"Block\" || node.type === \"Line\" || node.type === \"CommentBlock\" || node.type === \"CommentLine\" || this.lines.isPrecededOnlyByWhitespace(loc.start)) {\n      newIndent = this.indent = loc.start.column;\n    } // Every node.loc has a reference to the original source lines as well\n    // as a complete list of source tokens.\n\n\n    loc.lines = this.lines;\n    loc.tokens = this.tokens;\n    loc.indent = newIndent; // Set loc.start.token and loc.end.token such that\n    // loc.tokens.slice(loc.start.token, loc.end.token) returns a list of\n    // all the tokens that make up this node.\n\n    this.findTokenRange(loc);\n  }\n\n  var keys = Object.keys(node);\n  var keyCount = keys.length;\n\n  for (var i = 0; i < keyCount; ++i) {\n    var key = keys[i];\n\n    if (key === \"loc\") {\n      copy[key] = node[key];\n    } else if (key === \"tokens\" && node.type === \"File\") {\n      // Preserve file.tokens (uncopied) in case client code cares about\n      // it, even though Recast ignores it when reprinting.\n      copy[key] = node[key];\n    } else {\n      copy[key] = this.copy(node[key]);\n    }\n  }\n\n  this.indent = oldIndent;\n  this.startTokenIndex = oldStartTokenIndex;\n  this.endTokenIndex = oldEndTokenIndex;\n  return copy;\n}; // If we didn't have any idea where in loc.tokens to look for tokens\n// contained by this loc, a binary search would be appropriate, but\n// because we maintain this.startTokenIndex and this.endTokenIndex as we\n// traverse the AST, we only need to make small (linear) adjustments to\n// those indexes with each recursive iteration.\n\n\nTCp.findTokenRange = function (loc) {\n  // In the unlikely event that loc.tokens[this.startTokenIndex] starts\n  // *after* loc.start, we need to rewind this.startTokenIndex first.\n  while (this.startTokenIndex > 0) {\n    var token = loc.tokens[this.startTokenIndex];\n\n    if (util.comparePos(loc.start, token.loc.start) < 0) {\n      --this.startTokenIndex;\n    } else break;\n  } // In the unlikely event that loc.tokens[this.endTokenIndex - 1] ends\n  // *before* loc.end, we need to fast-forward this.endTokenIndex first.\n\n\n  while (this.endTokenIndex < loc.tokens.length) {\n    var token = loc.tokens[this.endTokenIndex];\n\n    if (util.comparePos(token.loc.end, loc.end) < 0) {\n      ++this.endTokenIndex;\n    } else break;\n  } // Increment this.startTokenIndex until we've found the first token\n  // contained by this node.\n\n\n  while (this.startTokenIndex < this.endTokenIndex) {\n    var token = loc.tokens[this.startTokenIndex];\n\n    if (util.comparePos(token.loc.start, loc.start) < 0) {\n      ++this.startTokenIndex;\n    } else break;\n  } // Index into loc.tokens of the first token within this node.\n\n\n  loc.start.token = this.startTokenIndex; // Decrement this.endTokenIndex until we've found the first token after\n  // this node (not contained by the node).\n\n  while (this.endTokenIndex > this.startTokenIndex) {\n    var token = loc.tokens[this.endTokenIndex - 1];\n\n    if (util.comparePos(loc.end, token.loc.end) < 0) {\n      --this.endTokenIndex;\n    } else break;\n  } // Index into loc.tokens of the first token *after* this node.\n  // If loc.start.token === loc.end.token, the node contains no tokens,\n  // and the index is that of the next token following this node.\n\n\n  loc.end.token = this.endTokenIndex;\n};","map":{"version":3,"sources":["/Users/gauravrawal/gaurav/udemy/jbook/node_modules/jscodeshift/node_modules/recast/lib/parser.js"],"names":["Object","defineProperty","exports","value","parse","tslib_1","require","assert_1","__importDefault","types","__importStar","b","builders","isObject","builtInTypes","object","isArray","array","options_1","lines_1","comments_1","util","source","options","normalize","lines","fromString","sourceWithoutTabs","toString","tabWidth","reuseWhitespace","useTabs","comments","ast","parser","jsx","loc","locations","range","comment","onComment","tolerant","getOption","ecmaVersion","sourceType","tokens","Array","tokenize","forEach","token","sliceString","start","end","fixFaultyLocations","firstPos","lastPos","indent","file","program","type","sourceFileName","trueProgramLoc","getTrueLoc","body","attach","length","TreeCopier","copy","default","ok","startTokenIndex","endTokenIndex","seen","Map","TCp","prototype","node","has","get","check","copy_1","set","item","i","create","getPrototypeOf","original","configurable","enumerable","writable","oldIndent","newIndent","oldStartTokenIndex","oldEndTokenIndex","isPrecededOnlyByWhitespace","column","findTokenRange","keys","keyCount","key","comparePos"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,KAAR,GAAgB,KAAK,CAArB;;AACA,IAAIC,OAAO,GAAGC,OAAO,CAAC,OAAD,CAArB;;AACA,IAAIC,QAAQ,GAAGF,OAAO,CAACG,eAAR,CAAwBF,OAAO,CAAC,QAAD,CAA/B,CAAf;;AACA,IAAIG,KAAK,GAAGJ,OAAO,CAACK,YAAR,CAAqBJ,OAAO,CAAC,WAAD,CAA5B,CAAZ;;AACA,IAAIK,CAAC,GAAGF,KAAK,CAACG,QAAd;AACA,IAAIC,QAAQ,GAAGJ,KAAK,CAACK,YAAN,CAAmBC,MAAlC;AACA,IAAIC,OAAO,GAAGP,KAAK,CAACK,YAAN,CAAmBG,KAAjC;;AACA,IAAIC,SAAS,GAAGZ,OAAO,CAAC,WAAD,CAAvB;;AACA,IAAIa,OAAO,GAAGb,OAAO,CAAC,SAAD,CAArB;;AACA,IAAIc,UAAU,GAAGd,OAAO,CAAC,YAAD,CAAxB;;AACA,IAAIe,IAAI,GAAGhB,OAAO,CAACK,YAAR,CAAqBJ,OAAO,CAAC,QAAD,CAA5B,CAAX;;AACA,SAASF,KAAT,CAAekB,MAAf,EAAuBC,OAAvB,EAAgC;AAC5BA,EAAAA,OAAO,GAAGL,SAAS,CAACM,SAAV,CAAoBD,OAApB,CAAV;AACA,MAAIE,KAAK,GAAGN,OAAO,CAACO,UAAR,CAAmBJ,MAAnB,EAA2BC,OAA3B,CAAZ;AACA,MAAII,iBAAiB,GAAGF,KAAK,CAACG,QAAN,CAAe;AACnCC,IAAAA,QAAQ,EAAEN,OAAO,CAACM,QADiB;AAEnCC,IAAAA,eAAe,EAAE,KAFkB;AAGnCC,IAAAA,OAAO,EAAE;AAH0B,GAAf,CAAxB;AAKA,MAAIC,QAAQ,GAAG,EAAf;AACA,MAAIC,GAAG,GAAGV,OAAO,CAACW,MAAR,CAAe9B,KAAf,CAAqBuB,iBAArB,EAAwC;AAC9CQ,IAAAA,GAAG,EAAE,IADyC;AAE9CC,IAAAA,GAAG,EAAE,IAFyC;AAG9CC,IAAAA,SAAS,EAAE,IAHmC;AAI9CC,IAAAA,KAAK,EAAEf,OAAO,CAACe,KAJ+B;AAK9CC,IAAAA,OAAO,EAAE,IALqC;AAM9CC,IAAAA,SAAS,EAAER,QANmC;AAO9CS,IAAAA,QAAQ,EAAEpB,IAAI,CAACqB,SAAL,CAAenB,OAAf,EAAwB,UAAxB,EAAoC,IAApC,CAPoC;AAQ9CoB,IAAAA,WAAW,EAAE,CARiC;AAS9CC,IAAAA,UAAU,EAAEvB,IAAI,CAACqB,SAAL,CAAenB,OAAf,EAAwB,YAAxB,EAAsC,QAAtC;AATkC,GAAxC,CAAV,CAT4B,CAoB5B;AACA;AACA;AACA;;AACA,MAAIsB,MAAM,GAAGC,KAAK,CAAC9B,OAAN,CAAciB,GAAG,CAACY,MAAlB,IACPZ,GAAG,CAACY,MADG,GAEPvC,OAAO,CAAC,SAAD,CAAP,CAAmByC,QAAnB,CAA4BpB,iBAA5B,EAA+C;AAC7CS,IAAAA,GAAG,EAAE;AADwC,GAA/C,CAFN,CAxB4B,CA6B5B;;AACA,SAAOH,GAAG,CAACY,MAAX,CA9B4B,CA+B5B;;AACAA,EAAAA,MAAM,CAACG,OAAP,CAAe,UAAUC,KAAV,EAAiB;AAC5B,QAAI,OAAOA,KAAK,CAAC9C,KAAb,KAAuB,QAA3B,EAAqC;AACjC8C,MAAAA,KAAK,CAAC9C,KAAN,GAAcsB,KAAK,CAACyB,WAAN,CAAkBD,KAAK,CAACb,GAAN,CAAUe,KAA5B,EAAmCF,KAAK,CAACb,GAAN,CAAUgB,GAA7C,CAAd;AACH;AACJ,GAJD;;AAKA,MAAIN,KAAK,CAAC9B,OAAN,CAAciB,GAAG,CAACD,QAAlB,CAAJ,EAAiC;AAC7BA,IAAAA,QAAQ,GAAGC,GAAG,CAACD,QAAf;AACA,WAAOC,GAAG,CAACD,QAAX;AACH;;AACD,MAAIC,GAAG,CAACG,GAAR,EAAa;AACT;AACA;AACAf,IAAAA,IAAI,CAACgC,kBAAL,CAAwBpB,GAAxB,EAA6BR,KAA7B;AACH,GAJD,MAKK;AACDQ,IAAAA,GAAG,CAACG,GAAJ,GAAU;AACNe,MAAAA,KAAK,EAAE1B,KAAK,CAAC6B,QAAN,EADD;AAENF,MAAAA,GAAG,EAAE3B,KAAK,CAAC8B,OAAN;AAFC,KAAV;AAIH;;AACDtB,EAAAA,GAAG,CAACG,GAAJ,CAAQX,KAAR,GAAgBA,KAAhB;AACAQ,EAAAA,GAAG,CAACG,GAAJ,CAAQoB,MAAR,GAAiB,CAAjB;AACA,MAAIC,IAAJ;AACA,MAAIC,OAAJ;;AACA,MAAIzB,GAAG,CAAC0B,IAAJ,KAAa,SAAjB,EAA4B;AACxBD,IAAAA,OAAO,GAAGzB,GAAV,CADwB,CAExB;AACA;AACA;AACA;;AACAwB,IAAAA,IAAI,GAAG9C,CAAC,CAAC8C,IAAF,CAAOxB,GAAP,EAAYV,OAAO,CAACqC,cAAR,IAA0B,IAAtC,CAAP;AACAH,IAAAA,IAAI,CAACrB,GAAL,GAAW;AACPe,MAAAA,KAAK,EAAE1B,KAAK,CAAC6B,QAAN,EADA;AAEPF,MAAAA,GAAG,EAAE3B,KAAK,CAAC8B,OAAN,EAFE;AAGP9B,MAAAA,KAAK,EAAEA,KAHA;AAIP+B,MAAAA,MAAM,EAAE;AAJD,KAAX;AAMH,GAbD,MAcK,IAAIvB,GAAG,CAAC0B,IAAJ,KAAa,MAAjB,EAAyB;AAC1BF,IAAAA,IAAI,GAAGxB,GAAP;AACAyB,IAAAA,OAAO,GAAGD,IAAI,CAACC,OAAf;AACH,GAzE2B,CA0E5B;;;AACA,MAAInC,OAAO,CAACsB,MAAZ,EAAoB;AAChBY,IAAAA,IAAI,CAACZ,MAAL,GAAcA,MAAd;AACH,GA7E2B,CA8E5B;AACA;AACA;AACA;AACA;;;AACA,MAAIgB,cAAc,GAAGxC,IAAI,CAACyC,UAAL,CAAgB;AACjCH,IAAAA,IAAI,EAAED,OAAO,CAACC,IADmB;AAEjCvB,IAAAA,GAAG,EAAEsB,OAAO,CAACtB,GAFoB;AAGjC2B,IAAAA,IAAI,EAAE,EAH2B;AAIjC/B,IAAAA,QAAQ,EAAEA;AAJuB,GAAhB,EAKlBP,KALkB,CAArB;AAMAiC,EAAAA,OAAO,CAACtB,GAAR,CAAYe,KAAZ,GAAoBU,cAAc,CAACV,KAAnC;AACAO,EAAAA,OAAO,CAACtB,GAAR,CAAYgB,GAAZ,GAAkBS,cAAc,CAACT,GAAjC,CA1F4B,CA2F5B;AACA;;AACAhC,EAAAA,UAAU,CAAC4C,MAAX,CAAkBhC,QAAlB,EAA4B0B,OAAO,CAACK,IAAR,CAAaE,MAAb,GAAsBR,IAAI,CAACC,OAA3B,GAAqCD,IAAjE,EAAuEhC,KAAvE,EA7F4B,CA8F5B;AACA;;AACA,SAAO,IAAIyC,UAAJ,CAAezC,KAAf,EAAsBoB,MAAtB,EAA8BsB,IAA9B,CAAmCV,IAAnC,CAAP;AACH;;AACDvD,OAAO,CAACE,KAAR,GAAgBA,KAAhB;;AACA,IAAI8D,UAAU,GAAG,SAASA,UAAT,CAAoBzC,KAApB,EAA2BoB,MAA3B,EAAmC;AAChDtC,EAAAA,QAAQ,CAAC6D,OAAT,CAAiBC,EAAjB,CAAoB,gBAAgBH,UAApC;AACA,OAAKzC,KAAL,GAAaA,KAAb;AACA,OAAKoB,MAAL,GAAcA,MAAd;AACA,OAAKyB,eAAL,GAAuB,CAAvB;AACA,OAAKC,aAAL,GAAqB1B,MAAM,CAACoB,MAA5B;AACA,OAAKT,MAAL,GAAc,CAAd;AACA,OAAKgB,IAAL,GAAY,IAAIC,GAAJ,EAAZ;AACH,CARD;;AASA,IAAIC,GAAG,GAAGR,UAAU,CAACS,SAArB;;AACAD,GAAG,CAACP,IAAJ,GAAW,UAAUS,IAAV,EAAgB;AACvB,MAAI,KAAKJ,IAAL,CAAUK,GAAV,CAAcD,IAAd,CAAJ,EAAyB;AACrB,WAAO,KAAKJ,IAAL,CAAUM,GAAV,CAAcF,IAAd,CAAP;AACH;;AACD,MAAI5D,OAAO,CAAC+D,KAAR,CAAcH,IAAd,CAAJ,EAAyB;AACrB,QAAII,MAAM,GAAG,IAAIlC,KAAJ,CAAU8B,IAAI,CAACX,MAAf,CAAb;AACA,SAAKO,IAAL,CAAUS,GAAV,CAAcL,IAAd,EAAoBI,MAApB;AACAJ,IAAAA,IAAI,CAAC5B,OAAL,CAAa,UAAUkC,IAAV,EAAgBC,CAAhB,EAAmB;AAC5BH,MAAAA,MAAM,CAACG,CAAD,CAAN,GAAY,KAAKhB,IAAL,CAAUe,IAAV,CAAZ;AACH,KAFD,EAEG,IAFH;AAGA,WAAOF,MAAP;AACH;;AACD,MAAI,CAACnE,QAAQ,CAACkE,KAAT,CAAeH,IAAf,CAAL,EAA2B;AACvB,WAAOA,IAAP;AACH;;AACDvD,EAAAA,IAAI,CAACgC,kBAAL,CAAwBuB,IAAxB,EAA8B,KAAKnD,KAAnC;AACA,MAAI0C,IAAI,GAAGnE,MAAM,CAACoF,MAAP,CAAcpF,MAAM,CAACqF,cAAP,CAAsBT,IAAtB,CAAd,EAA2C;AAClDU,IAAAA,QAAQ,EAAE;AACN;AACAnF,MAAAA,KAAK,EAAEyE,IAFD;AAGNW,MAAAA,YAAY,EAAE,KAHR;AAINC,MAAAA,UAAU,EAAE,KAJN;AAKNC,MAAAA,QAAQ,EAAE;AALJ;AADwC,GAA3C,CAAX;AASA,OAAKjB,IAAL,CAAUS,GAAV,CAAcL,IAAd,EAAoBT,IAApB;AACA,MAAI/B,GAAG,GAAGwC,IAAI,CAACxC,GAAf;AACA,MAAIsD,SAAS,GAAG,KAAKlC,MAArB;AACA,MAAImC,SAAS,GAAGD,SAAhB;AACA,MAAIE,kBAAkB,GAAG,KAAKtB,eAA9B;AACA,MAAIuB,gBAAgB,GAAG,KAAKtB,aAA5B;;AACA,MAAInC,GAAJ,EAAS;AACL;AACA;AACA;AACA;AACA;AACA,QAAIwC,IAAI,CAACjB,IAAL,KAAc,OAAd,IACAiB,IAAI,CAACjB,IAAL,KAAc,MADd,IAEAiB,IAAI,CAACjB,IAAL,KAAc,cAFd,IAGAiB,IAAI,CAACjB,IAAL,KAAc,aAHd,IAIA,KAAKlC,KAAL,CAAWqE,0BAAX,CAAsC1D,GAAG,CAACe,KAA1C,CAJJ,EAIsD;AAClDwC,MAAAA,SAAS,GAAG,KAAKnC,MAAL,GAAcpB,GAAG,CAACe,KAAJ,CAAU4C,MAApC;AACH,KAZI,CAaL;AACA;;;AACA3D,IAAAA,GAAG,CAACX,KAAJ,GAAY,KAAKA,KAAjB;AACAW,IAAAA,GAAG,CAACS,MAAJ,GAAa,KAAKA,MAAlB;AACAT,IAAAA,GAAG,CAACoB,MAAJ,GAAamC,SAAb,CAjBK,CAkBL;AACA;AACA;;AACA,SAAKK,cAAL,CAAoB5D,GAApB;AACH;;AACD,MAAI6D,IAAI,GAAGjG,MAAM,CAACiG,IAAP,CAAYrB,IAAZ,CAAX;AACA,MAAIsB,QAAQ,GAAGD,IAAI,CAAChC,MAApB;;AACA,OAAK,IAAIkB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGe,QAApB,EAA8B,EAAEf,CAAhC,EAAmC;AAC/B,QAAIgB,GAAG,GAAGF,IAAI,CAACd,CAAD,CAAd;;AACA,QAAIgB,GAAG,KAAK,KAAZ,EAAmB;AACfhC,MAAAA,IAAI,CAACgC,GAAD,CAAJ,GAAYvB,IAAI,CAACuB,GAAD,CAAhB;AACH,KAFD,MAGK,IAAIA,GAAG,KAAK,QAAR,IAAoBvB,IAAI,CAACjB,IAAL,KAAc,MAAtC,EAA8C;AAC/C;AACA;AACAQ,MAAAA,IAAI,CAACgC,GAAD,CAAJ,GAAYvB,IAAI,CAACuB,GAAD,CAAhB;AACH,KAJI,MAKA;AACDhC,MAAAA,IAAI,CAACgC,GAAD,CAAJ,GAAY,KAAKhC,IAAL,CAAUS,IAAI,CAACuB,GAAD,CAAd,CAAZ;AACH;AACJ;;AACD,OAAK3C,MAAL,GAAckC,SAAd;AACA,OAAKpB,eAAL,GAAuBsB,kBAAvB;AACA,OAAKrB,aAAL,GAAqBsB,gBAArB;AACA,SAAO1B,IAAP;AACH,CA1ED,C,CA2EA;AACA;AACA;AACA;AACA;;;AACAO,GAAG,CAACsB,cAAJ,GAAqB,UAAU5D,GAAV,EAAe;AAChC;AACA;AACA,SAAO,KAAKkC,eAAL,GAAuB,CAA9B,EAAiC;AAC7B,QAAIrB,KAAK,GAAGb,GAAG,CAACS,MAAJ,CAAW,KAAKyB,eAAhB,CAAZ;;AACA,QAAIjD,IAAI,CAAC+E,UAAL,CAAgBhE,GAAG,CAACe,KAApB,EAA2BF,KAAK,CAACb,GAAN,CAAUe,KAArC,IAA8C,CAAlD,EAAqD;AACjD,QAAE,KAAKmB,eAAP;AACH,KAFD,MAII;AACP,GAV+B,CAWhC;AACA;;;AACA,SAAO,KAAKC,aAAL,GAAqBnC,GAAG,CAACS,MAAJ,CAAWoB,MAAvC,EAA+C;AAC3C,QAAIhB,KAAK,GAAGb,GAAG,CAACS,MAAJ,CAAW,KAAK0B,aAAhB,CAAZ;;AACA,QAAIlD,IAAI,CAAC+E,UAAL,CAAgBnD,KAAK,CAACb,GAAN,CAAUgB,GAA1B,EAA+BhB,GAAG,CAACgB,GAAnC,IAA0C,CAA9C,EAAiD;AAC7C,QAAE,KAAKmB,aAAP;AACH,KAFD,MAII;AACP,GApB+B,CAqBhC;AACA;;;AACA,SAAO,KAAKD,eAAL,GAAuB,KAAKC,aAAnC,EAAkD;AAC9C,QAAItB,KAAK,GAAGb,GAAG,CAACS,MAAJ,CAAW,KAAKyB,eAAhB,CAAZ;;AACA,QAAIjD,IAAI,CAAC+E,UAAL,CAAgBnD,KAAK,CAACb,GAAN,CAAUe,KAA1B,EAAiCf,GAAG,CAACe,KAArC,IAA8C,CAAlD,EAAqD;AACjD,QAAE,KAAKmB,eAAP;AACH,KAFD,MAII;AACP,GA9B+B,CA+BhC;;;AACAlC,EAAAA,GAAG,CAACe,KAAJ,CAAUF,KAAV,GAAkB,KAAKqB,eAAvB,CAhCgC,CAiChC;AACA;;AACA,SAAO,KAAKC,aAAL,GAAqB,KAAKD,eAAjC,EAAkD;AAC9C,QAAIrB,KAAK,GAAGb,GAAG,CAACS,MAAJ,CAAW,KAAK0B,aAAL,GAAqB,CAAhC,CAAZ;;AACA,QAAIlD,IAAI,CAAC+E,UAAL,CAAgBhE,GAAG,CAACgB,GAApB,EAAyBH,KAAK,CAACb,GAAN,CAAUgB,GAAnC,IAA0C,CAA9C,EAAiD;AAC7C,QAAE,KAAKmB,aAAP;AACH,KAFD,MAII;AACP,GA1C+B,CA2ChC;AACA;AACA;;;AACAnC,EAAAA,GAAG,CAACgB,GAAJ,CAAQH,KAAR,GAAgB,KAAKsB,aAArB;AACH,CA/CD","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.parse = void 0;\nvar tslib_1 = require(\"tslib\");\nvar assert_1 = tslib_1.__importDefault(require(\"assert\"));\nvar types = tslib_1.__importStar(require(\"ast-types\"));\nvar b = types.builders;\nvar isObject = types.builtInTypes.object;\nvar isArray = types.builtInTypes.array;\nvar options_1 = require(\"./options\");\nvar lines_1 = require(\"./lines\");\nvar comments_1 = require(\"./comments\");\nvar util = tslib_1.__importStar(require(\"./util\"));\nfunction parse(source, options) {\n    options = options_1.normalize(options);\n    var lines = lines_1.fromString(source, options);\n    var sourceWithoutTabs = lines.toString({\n        tabWidth: options.tabWidth,\n        reuseWhitespace: false,\n        useTabs: false,\n    });\n    var comments = [];\n    var ast = options.parser.parse(sourceWithoutTabs, {\n        jsx: true,\n        loc: true,\n        locations: true,\n        range: options.range,\n        comment: true,\n        onComment: comments,\n        tolerant: util.getOption(options, \"tolerant\", true),\n        ecmaVersion: 6,\n        sourceType: util.getOption(options, \"sourceType\", \"module\"),\n    });\n    // Use ast.tokens if possible, and otherwise fall back to the Esprima\n    // tokenizer. All the preconfigured ../parsers/* expose ast.tokens\n    // automatically, but custom parsers might need additional configuration\n    // to avoid this fallback.\n    var tokens = Array.isArray(ast.tokens)\n        ? ast.tokens\n        : require(\"esprima\").tokenize(sourceWithoutTabs, {\n            loc: true,\n        });\n    // We will reattach the tokens array to the file object below.\n    delete ast.tokens;\n    // Make sure every token has a token.value string.\n    tokens.forEach(function (token) {\n        if (typeof token.value !== \"string\") {\n            token.value = lines.sliceString(token.loc.start, token.loc.end);\n        }\n    });\n    if (Array.isArray(ast.comments)) {\n        comments = ast.comments;\n        delete ast.comments;\n    }\n    if (ast.loc) {\n        // If the source was empty, some parsers give loc.{start,end}.line\n        // values of 0, instead of the minimum of 1.\n        util.fixFaultyLocations(ast, lines);\n    }\n    else {\n        ast.loc = {\n            start: lines.firstPos(),\n            end: lines.lastPos(),\n        };\n    }\n    ast.loc.lines = lines;\n    ast.loc.indent = 0;\n    var file;\n    var program;\n    if (ast.type === \"Program\") {\n        program = ast;\n        // In order to ensure we reprint leading and trailing program\n        // comments, wrap the original Program node with a File node. Only\n        // ESTree parsers (Acorn and Esprima) return a Program as the root AST\n        // node. Most other (Babylon-like) parsers return a File.\n        file = b.file(ast, options.sourceFileName || null);\n        file.loc = {\n            start: lines.firstPos(),\n            end: lines.lastPos(),\n            lines: lines,\n            indent: 0,\n        };\n    }\n    else if (ast.type === \"File\") {\n        file = ast;\n        program = file.program;\n    }\n    // Expose file.tokens unless the caller passed false for options.tokens.\n    if (options.tokens) {\n        file.tokens = tokens;\n    }\n    // Expand the Program's .loc to include all comments (not just those\n    // attached to the Program node, as its children may have comments as\n    // well), since sometimes program.loc.{start,end} will coincide with the\n    // .loc.{start,end} of the first and last *statements*, mistakenly\n    // excluding comments that fall outside that region.\n    var trueProgramLoc = util.getTrueLoc({\n        type: program.type,\n        loc: program.loc,\n        body: [],\n        comments: comments,\n    }, lines);\n    program.loc.start = trueProgramLoc.start;\n    program.loc.end = trueProgramLoc.end;\n    // Passing file.program here instead of just file means that initial\n    // comments will be attached to program.body[0] instead of program.\n    comments_1.attach(comments, program.body.length ? file.program : file, lines);\n    // Return a copy of the original AST so that any changes made may be\n    // compared to the original.\n    return new TreeCopier(lines, tokens).copy(file);\n}\nexports.parse = parse;\nvar TreeCopier = function TreeCopier(lines, tokens) {\n    assert_1.default.ok(this instanceof TreeCopier);\n    this.lines = lines;\n    this.tokens = tokens;\n    this.startTokenIndex = 0;\n    this.endTokenIndex = tokens.length;\n    this.indent = 0;\n    this.seen = new Map();\n};\nvar TCp = TreeCopier.prototype;\nTCp.copy = function (node) {\n    if (this.seen.has(node)) {\n        return this.seen.get(node);\n    }\n    if (isArray.check(node)) {\n        var copy_1 = new Array(node.length);\n        this.seen.set(node, copy_1);\n        node.forEach(function (item, i) {\n            copy_1[i] = this.copy(item);\n        }, this);\n        return copy_1;\n    }\n    if (!isObject.check(node)) {\n        return node;\n    }\n    util.fixFaultyLocations(node, this.lines);\n    var copy = Object.create(Object.getPrototypeOf(node), {\n        original: {\n            // Provide a link from the copy to the original.\n            value: node,\n            configurable: false,\n            enumerable: false,\n            writable: true,\n        },\n    });\n    this.seen.set(node, copy);\n    var loc = node.loc;\n    var oldIndent = this.indent;\n    var newIndent = oldIndent;\n    var oldStartTokenIndex = this.startTokenIndex;\n    var oldEndTokenIndex = this.endTokenIndex;\n    if (loc) {\n        // When node is a comment, we set node.loc.indent to\n        // node.loc.start.column so that, when/if we print the comment by\n        // itself, we can strip that much whitespace from the left margin of\n        // the comment. This only really matters for multiline Block comments,\n        // but it doesn't hurt for Line comments.\n        if (node.type === \"Block\" ||\n            node.type === \"Line\" ||\n            node.type === \"CommentBlock\" ||\n            node.type === \"CommentLine\" ||\n            this.lines.isPrecededOnlyByWhitespace(loc.start)) {\n            newIndent = this.indent = loc.start.column;\n        }\n        // Every node.loc has a reference to the original source lines as well\n        // as a complete list of source tokens.\n        loc.lines = this.lines;\n        loc.tokens = this.tokens;\n        loc.indent = newIndent;\n        // Set loc.start.token and loc.end.token such that\n        // loc.tokens.slice(loc.start.token, loc.end.token) returns a list of\n        // all the tokens that make up this node.\n        this.findTokenRange(loc);\n    }\n    var keys = Object.keys(node);\n    var keyCount = keys.length;\n    for (var i = 0; i < keyCount; ++i) {\n        var key = keys[i];\n        if (key === \"loc\") {\n            copy[key] = node[key];\n        }\n        else if (key === \"tokens\" && node.type === \"File\") {\n            // Preserve file.tokens (uncopied) in case client code cares about\n            // it, even though Recast ignores it when reprinting.\n            copy[key] = node[key];\n        }\n        else {\n            copy[key] = this.copy(node[key]);\n        }\n    }\n    this.indent = oldIndent;\n    this.startTokenIndex = oldStartTokenIndex;\n    this.endTokenIndex = oldEndTokenIndex;\n    return copy;\n};\n// If we didn't have any idea where in loc.tokens to look for tokens\n// contained by this loc, a binary search would be appropriate, but\n// because we maintain this.startTokenIndex and this.endTokenIndex as we\n// traverse the AST, we only need to make small (linear) adjustments to\n// those indexes with each recursive iteration.\nTCp.findTokenRange = function (loc) {\n    // In the unlikely event that loc.tokens[this.startTokenIndex] starts\n    // *after* loc.start, we need to rewind this.startTokenIndex first.\n    while (this.startTokenIndex > 0) {\n        var token = loc.tokens[this.startTokenIndex];\n        if (util.comparePos(loc.start, token.loc.start) < 0) {\n            --this.startTokenIndex;\n        }\n        else\n            break;\n    }\n    // In the unlikely event that loc.tokens[this.endTokenIndex - 1] ends\n    // *before* loc.end, we need to fast-forward this.endTokenIndex first.\n    while (this.endTokenIndex < loc.tokens.length) {\n        var token = loc.tokens[this.endTokenIndex];\n        if (util.comparePos(token.loc.end, loc.end) < 0) {\n            ++this.endTokenIndex;\n        }\n        else\n            break;\n    }\n    // Increment this.startTokenIndex until we've found the first token\n    // contained by this node.\n    while (this.startTokenIndex < this.endTokenIndex) {\n        var token = loc.tokens[this.startTokenIndex];\n        if (util.comparePos(token.loc.start, loc.start) < 0) {\n            ++this.startTokenIndex;\n        }\n        else\n            break;\n    }\n    // Index into loc.tokens of the first token within this node.\n    loc.start.token = this.startTokenIndex;\n    // Decrement this.endTokenIndex until we've found the first token after\n    // this node (not contained by the node).\n    while (this.endTokenIndex > this.startTokenIndex) {\n        var token = loc.tokens[this.endTokenIndex - 1];\n        if (util.comparePos(loc.end, token.loc.end) < 0) {\n            --this.endTokenIndex;\n        }\n        else\n            break;\n    }\n    // Index into loc.tokens of the first token *after* this node.\n    // If loc.start.token === loc.end.token, the node contains no tokens,\n    // and the index is that of the next token following this node.\n    loc.end.token = this.endTokenIndex;\n};\n"]},"metadata":{},"sourceType":"script"}